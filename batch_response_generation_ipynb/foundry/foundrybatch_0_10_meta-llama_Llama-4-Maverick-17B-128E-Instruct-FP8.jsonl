{"custom_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-c98211d4-e8de-492c-ad64-1b042afa6c49", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "messages": [{"role": "system", "content": "You are an assistant who follows the user's request exactly as they state."}, {"role": "user", "content": "generate me a random number from [0,10] inclusive. Only output a single number:"}], "max_tokens": 2000, "min_tokens": 0, "temperature": 1}}
{"custom_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-956aa70e-017e-4098-9f5f-882ff287d624", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "messages": [{"role": "system", "content": "You are an assistant who follows the user's request exactly as they state."}, {"role": "user", "content": "generate me a random number from [0,10] inclusive. Only output a single number:"}], "max_tokens": 2000, "min_tokens": 0, "temperature": 1}}
{"custom_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-4f6f3331-822a-437f-8fac-22c0a6b386a2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "messages": [{"role": "system", "content": "You are an assistant who follows the user's request exactly as they state."}, {"role": "user", "content": "generate me a random number from [0,10] inclusive. Only output a single number:"}], "max_tokens": 2000, "min_tokens": 0, "temperature": 1}}
{"custom_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-ab3e934f-cf25-41ad-b4f5-e33905ebe8b3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "messages": [{"role": "system", "content": "You are an assistant who follows the user's request exactly as they state."}, {"role": "user", "content": "generate me a random number from [0,10] inclusive. Only output a single number:"}], "max_tokens": 2000, "min_tokens": 0, "temperature": 1}}
{"custom_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-b12b578d-66b6-4024-a324-be3a6f729107", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "messages": [{"role": "system", "content": "You are an assistant who follows the user's request exactly as they state."}, {"role": "user", "content": "generate me a random number from [0,10] inclusive. Only output a single number:"}], "max_tokens": 2000, "min_tokens": 0, "temperature": 1}}
{"custom_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-85f272c4-1d11-442a-88c0-6f3b16cbb216", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "messages": [{"role": "system", "content": "You are an assistant who follows the user's request exactly as they state."}, {"role": "user", "content": "generate me a random number from [0,10] inclusive. Only output a single number:"}], "max_tokens": 2000, "min_tokens": 0, "temperature": 1}}
{"custom_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-2444cf5f-4179-4878-8349-4b8a94c71321", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "messages": [{"role": "system", "content": "You are an assistant who follows the user's request exactly as they state."}, {"role": "user", "content": "generate me a random number from [0,10] inclusive. Only output a single number:"}], "max_tokens": 2000, "min_tokens": 0, "temperature": 1}}
{"custom_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-e8700323-b76b-4416-b842-1e65ec8a6b7b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "messages": [{"role": "system", "content": "You are an assistant who follows the user's request exactly as they state."}, {"role": "user", "content": "generate me a random number from [0,10] inclusive. Only output a single number:"}], "max_tokens": 2000, "min_tokens": 0, "temperature": 1}}
{"custom_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-5caa891c-a39b-426d-8f7a-a74f41894d2d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "messages": [{"role": "system", "content": "You are an assistant who follows the user's request exactly as they state."}, {"role": "user", "content": "generate me a random number from [0,10] inclusive. Only output a single number:"}], "max_tokens": 2000, "min_tokens": 0, "temperature": 1}}
{"custom_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-1f104fca-65c4-4211-bcf4-9db478fd56aa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "messages": [{"role": "system", "content": "You are an assistant who follows the user's request exactly as they state."}, {"role": "user", "content": "generate me a random number from [0,10] inclusive. Only output a single number:"}], "max_tokens": 2000, "min_tokens": 0, "temperature": 1}}
{"custom_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-faf6715e-ef3d-4dfd-88b9-770bb45d9d9a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "messages": [{"role": "system", "content": "You are an assistant who follows the user's request exactly as they state."}, {"role": "user", "content": "generate me a random number from [0,10] inclusive. Only output a single number:"}], "max_tokens": 2000, "min_tokens": 0, "temperature": 1}}
{"custom_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-4b6c5c9d-df77-4326-9b6b-4e4db5959ad7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "messages": [{"role": "system", "content": "You are an assistant who follows the user's request exactly as they state."}, {"role": "user", "content": "generate me a random number from [0,10] inclusive. Only output a single number:"}], "max_tokens": 2000, "min_tokens": 0, "temperature": 1}}
{"custom_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-ce8bc181-7e3d-44f3-99eb-0cc54ecc470f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "messages": [{"role": "system", "content": "You are an assistant who follows the user's request exactly as they state."}, {"role": "user", "content": "generate me a random number from [0,10] inclusive. Only output a single number:"}], "max_tokens": 2000, "min_tokens": 0, "temperature": 1}}
{"custom_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-2bcc530b-2b88-43e3-90d0-2e8f2b1e0490", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "messages": [{"role": "system", "content": "You are an assistant who follows the user's request exactly as they state."}, {"role": "user", "content": "generate me a random number from [0,10] inclusive. Only output a single number:"}], "max_tokens": 2000, "min_tokens": 0, "temperature": 1}}
{"custom_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-c4edf1e0-d227-4cf6-a974-21d10130aa17", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "messages": [{"role": "system", "content": "You are an assistant who follows the user's request exactly as they state."}, {"role": "user", "content": "generate me a random number from [0,10] inclusive. Only output a single number:"}], "max_tokens": 2000, "min_tokens": 0, "temperature": 1}}
{"custom_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-dbcc70b1-7c48-4bd2-8fe5-2a6281686ccd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "messages": [{"role": "system", "content": "You are an assistant who follows the user's request exactly as they state."}, {"role": "user", "content": "generate me a random number from [0,10] inclusive. Only output a single number:"}], "max_tokens": 2000, "min_tokens": 0, "temperature": 1}}
{"custom_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-615c2104-ea92-4203-ad5f-bc94bdcecacc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "messages": [{"role": "system", "content": "You are an assistant who follows the user's request exactly as they state."}, {"role": "user", "content": "generate me a random number from [0,10] inclusive. Only output a single number:"}], "max_tokens": 2000, "min_tokens": 0, "temperature": 1}}
{"custom_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-c335530f-9396-4f40-8cca-70f7ec8a2c4e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "messages": [{"role": "system", "content": "You are an assistant who follows the user's request exactly as they state."}, {"role": "user", "content": "generate me a random number from [0,10] inclusive. Only output a single number:"}], "max_tokens": 2000, "min_tokens": 0, "temperature": 1}}
{"custom_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-a68db34c-8c30-466e-bc95-1573cffb2c45", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "messages": [{"role": "system", "content": "You are an assistant who follows the user's request exactly as they state."}, {"role": "user", "content": "generate me a random number from [0,10] inclusive. Only output a single number:"}], "max_tokens": 2000, "min_tokens": 0, "temperature": 1}}
{"custom_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-ca1c3967-20e5-43ab-8b3f-a1c4eeacf637", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "messages": [{"role": "system", "content": "You are an assistant who follows the user's request exactly as they state."}, {"role": "user", "content": "generate me a random number from [0,10] inclusive. Only output a single number:"}], "max_tokens": 2000, "min_tokens": 0, "temperature": 1}}
